---
title: Getting Started
description: Step-by-step guide showing how to add Kubernetes Kit
  to your application.
order: 10
---

= Getting Started with Kubernetes Kit
:sectnums:

Kubernetes Kit provides high availability for Vaadin applications
 running in a Kubernetes cluster (including Azure).

This tutorial guides you through setting up and deploying
 an application with Kubernetes Kit in a local Kubernetes
 cluster.

== Requirements

This tutorial assumes that you have the following software
 installed on your local machine:

- https://www.docker.com/products/docker-desktop/[Docker Desktop^]
- A local Kubernetes cluster such as
 https://minikube.sigs.k8s.io/docs/start/[minikube^],
 https://kind.sigs.k8s.io/docs/user/quick-start/[kind^] or
 https://docs.docker.com/desktop/kubernetes/[Docker^] itself.

== Setting Up a Vaadin Project

Download a new Vaadin project from https://start.vaadin.com/[^].

== Add the Kubernetes Kit Dependency

To get started you first need to add Kubernetes Kit as a
 dependency to the application:

.pom.xml
[source,xml]
----
<dependency>
  <groupId>com.vaadin</groupId>
  <artifactId>kubernetes-kit-starter</artifactId>
</dependency>
----

Add the following to the application configuration file:

.application.properties
[source,properties]
vaadin.serialization.include-packages=com.example.application
vaadin.devmode.sessionSerialization.enabled=true

[NOTE]
====
The `include-packages` property is used by the session serialization to limit the classes inspected for transient fields. In this case, it is being limited to classes within the starter project. For more information, see <<{articles}/tools/kubernetes/session-replication#kubernetes-kit-session-replication,session replication>>.

The second property enables session serialization debug tool while in development.

====

== Session Replication Backend

Kubernetes Kit enables high availability and the possibility to scale applications up and down in a Kubernetes cluster by storing session data in a backend that is accessible to the cluster. Note that you don't need to enable session replication if you are only interested in using the <<{articles}/tools/kubernetes/update-version#,rolling update feature>> of the Kit.

This tutorial uses Hazelcast for this purpose. However, Redis is also supported.

You need to add the Hazelcast dependency to the application:

.pom.xml
[source,xml]
----
<dependency>
    <groupId>com.hazelcast</groupId>
    <artifactId>hazelcast</artifactId>
</dependency>
----

Next, you need to add the following to the application
configuration file:

.application.properties
[source,properties]
----
vaadin.kubernetes.hazelcast.service-name=hazelcast-service
----

Deploy the Hazelcast role to the cluster:

[source,terminal]
kubectl apply -f https://raw.githubusercontent.com/hazelcast/hazelcast/master/kubernetes-rbac.yaml

[NOTE]
====
If you want to deploy this to another namespace than `default`,
you need to download the yaml file https://raw.githubusercontent.com/hazelcast/hazelcast/master/kubernetes-rbac.yaml[here^]
and edit the hard-coded namespace. Then deploy to your cluster:

[source,terminal]
kubectl apply -f kubernetes-rbac.yaml
====

Then you need to deploy a load balancer service to your
 cluster. Create the following Kubernetes manifest file:

.hazelcast.yaml
[source,yaml]
----
apiVersion: v1
kind: Service
metadata:
  name: hazelcast-service
spec:
  selector:
    app: my-app
  ports:
    - name: hazelcast
      port: 5701
  type: LoadBalancer
----

And deploy the manifest to your cluster:

[source,terminal]
kubectl apply -f hazelcast.yaml

You should now see the load balancer service:
[source,terminal]
kubectl get svc hazelcast-service

[source,terminal]
----
NAME                TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
hazelcast-service   LoadBalancer   10.96.178.190   <pending>     5701:31516/TCP   18h
----

== Build and Deploy the Application

The next step is to build a container image of the
application and deploy it to your Kubernetes cluster.

Clean and package the application for production:

[source,terminal]
mvn clean package -Pproduction

Create the following `Dockerfile` file and place it in the
 main directory of the application:

[source,Dockerfile]
----
FROM openjdk:17-jdk-slim
COPY target/*.jar /usr/app/app.jar
RUN useradd -m myuser
USER myuser
EXPOSE 8080
CMD java -jar /usr/app/app.jar
----

Open a terminal to the main directory and use Docker to
build a container image for the application and tag it with
version 1.0.0 (note the required period at the end):

[source,terminal]
docker build -t my-app:1.0.0 .

[NOTE]
====
Depending on the Kubernetes cluster you are using, you may
need to publish the image to a local registry or push the
image to the cluster. Otherwise, the image cannot not be
found. Please refer to your cluster documentation.

If you are using kind on a local machine, you need to load the image to the cluster like this:

[source,terminal]
kind load docker-image my-app:1.0.0
====

Now create a deployment manifest for the application:

.app-v1.yaml
[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app-v1
spec:
  replicas: 4
  selector:
    matchLabels:
      app: my-app
      version: 1.0.0
  template:
    metadata:
      labels:
        app: my-app
        version: 1.0.0
    spec:
      containers:
        - name: my-app
          image: my-app:1.0.0
          imagePullPolicy: IfNotPresent
          env:
            - name: APP_VERSION
              value: 1.0.0
          ports:
            - name: http
              containerPort: 8080
            - name: multicast
              containerPort: 5701
---
apiVersion: v1
kind: Service
metadata:
  name: my-app-v1
spec:
  selector:
    app: my-app
    version: 1.0.0
  ports:
    - name: http
      port: 80
      targetPort: http
----

[NOTE]
The multicast port (5701) is only used for session
replication using Hazelcast.

Deploy the manifest to your cluster:

[source,terminal]
kubectl apply -f app-v1.yaml

You should now see 4 pods running in the cluster, for example:
[source,terminal]
kubectl get pods

[source,terminal]
----
NAME                            READY   STATUS    RESTARTS      AGE
my-app-v1-f87bfcbb4-5qjml       1/1     Running   0             22s
my-app-v1-f87bfcbb4-czkzr       1/1     Running   0             22s
my-app-v1-f87bfcbb4-gjqw6       1/1     Running   0             22s
my-app-v1-f87bfcbb4-rxvjb       1/1     Running   0             22s
----

== Ingress Rules

In order to access the application, you need to provide some
ingress rules.

If you don't already have `ingress-nginx` installed in your
cluster, install it with the following command:

[source,terminal]
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.4.0/deploy/static/provider/cloud/deploy.yaml

Then create an ingress rule manifest file:

.ingress-v1.yaml
[source,yaml]
----
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-app
  annotations:
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/affinity: "cookie"
    nginx.ingress.kubernetes.io/affinity-mode: "persistent"
spec:
  rules:
    - http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: my-app-v1
                port:
                  number: 80
----

Deploy the manifest to your cluster:

[source,terminal]
kubectl apply -f ingress-v1.yaml

The application should now be available at http://localhost[^]

[NOTE]
====
In order to access the application from your local machine,
it may be necessary to use the `port-forward` utility. In
this case use the following command:

[source,terminal]
kubectl port-forward -n ingress-nginx service/ingress-nginx-controller 8080:80

The application should now be available at http://localhost:8080[^]
====

== Scaling the Application

You can use `kubectl` commands to increase or reduce
the amount of pods used by the deployment. For example, the
following command increases the number of pods to 5:

[source,terminal]
kubectl scale deployment/my-app-v1 --replicas=5

You can also simulate the failure of a specific pod by deleting
 it by name:

[source,terminal]
kubectl delete pod/<pod-name>

.Replace placeholder pod name
[NOTE]
Remember to substitute the name of your application pod.

If you have enabled session replication, this can be used
to check that it is performing as expected. If you open the
application and then delete the pod it is connected to,
when you perform the next action, you should not lose
session data.

== Next Steps

The Kubernetes Kit can also help you roll out a new version of
your application in a Kubernetes cluster.

xref:update-version#[New Version Roll Out, role="button secondary water"]
